1
00:00:00,000 --> 00:00:03,254
你的数据应该能代表你要解决的问题

2
00:00:03,254 --> 00:00:05,685
要能适用于你的业务场景

3
00:00:05,684 --> 00:00:09,269
你不可能用虚拟数据来训练一个真实的模型

4
00:00:09,269 --> 00:00:13,814
你需要用真实数据来确保训练数据与真实场景是契合的

5
00:00:13,814 --> 00:00:16,259
同时 你需要制定模型的成功标准

6
00:00:16,260 --> 00:00:18,645
通常是基于：精度(precision)、

7
00:00:18,644 --> 00:00:20,535
召回率(recall) 以及 F1 score

8
00:00:20,535 --> 00:00:23,460
如果你判断模型没有达到这些标准

9
00:00:23,460 --> 00:00:25,740
你需要重新审视数据　并重新训练

10
00:00:25,739 --> 00:00:27,989
后续操作可能是：包括更多的极端示例

11
00:00:27,989 --> 00:00:30,929
包括模型表现差的那些类别的更多示例

12
00:00:30,929 --> 00:00:33,869
或者进一步澄清类别间的不同点

13
00:00:33,869 --> 00:00:36,809
混淆矩阵(confusion matrix) 可以帮助你理解模型的精度和召回率

14
00:00:36,810 --> 00:00:39,870
需要计算 正确判断例子的数量
包括 真正例 - True Positives\TP 和 真假例 - True Negatives\TN

15
00:00:39,869 --> 00:00:42,314
以及 判断错误的例子数量
包括 漏判 - False Negatives\FN 和 误判 - False Positives\FP

16
00:00:42,314 --> 00:00:47,265
精度代表模型预测为真的所有例子里 模型正确的比例

17
00:00:47,265 --> 00:00:51,355
计算公式：真正例 占 所有模型预测为真的例子 的比例 即 TP\(TP+FP)

18
00:00:51,354 --> 00:00:53,034
所以在这个例子里 

19
00:00:53,034 --> 00:01:00,474
精度 = 45 / (45+15) = 75%

20
00:01:00,475 --> 00:01:04,689
召回率代表 对于所有实际为真的例子 你的模型能测出多少？

21
00:01:04,689 --> 00:01:09,024
计算公式：真正例 占 所有实际为真的例子 的比例 即 TP\(TP+FN)

22
00:01:09,025 --> 00:01:14,844
召回率 = 45 / (45+5) = 90%

23
00:01:14,844 --> 00:01:19,060
F1 score 就是精确值和召回率的调和均值

24
00:01:19,060 --> 00:01:22,810
因为通常需要权衡取舍 并且希望获得更高的精度或召回率

25
00:01:22,810 --> 00:01:25,820
所以目标是提高 F1 score

